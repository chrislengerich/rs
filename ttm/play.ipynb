{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b021b4-b6f1-441c-b1fa-9a0f028ccdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "/home/ubuntu/ttm\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522c1d29-328f-4ab2-9e69-d61f4e91ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd711d16-88b7-415c-92b6-7059efc30e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import textworld.gym\n",
    "import time\n",
    "import agent\n",
    "from trajectory import Trajectory, Rollout, Goal\n",
    "from typing import List\n",
    "\n",
    "import pdb, sys\n",
    "\n",
    "# Register a text-based game as a new Gym's environment.\n",
    "env_id = textworld.gym.register_game(\"../tw_games/tw-coin_collector-r2ipdI3j-house-mo-xEEPcbKpfN1RibBb.z8\",\n",
    "                                     max_episode_steps=50)\n",
    "\n",
    "tokenizer, generator = agent.init_models(device=0)\n",
    "env = gym.make(env_id)  # Start the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda414f9-2d9b-4754-bbf2-9d014ce41023",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "124.439808\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "124.439808\n",
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "skipping\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "l = [module for module in generator.model.modules() if not isinstance(module, nn.Sequential)]\n",
    "print(len(l))\n",
    "for li in l:\n",
    "    try:\n",
    "        print(li.num_parameters()/1.E6)\n",
    "        print(li)\n",
    "    except Exception:\n",
    "        print(\"skipping\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785703b0-bd9a-4049-8ea1-b20891db6d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "training_data = IMDB(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e46fe6-00c5-48f2-aad1-08cfde8d1bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: I cant believe blockbuster carries this movie. It was SO BAD. I was totally fooled by the box art. DON'T BE FOOLED!! Its not worth your time I promise you. I don't know if the positive reviews for this flick DONE REVIEW \", 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: Seriously crappy movie.<br /><br />First off, the movie starts with a cop and his partner parked outside of a warehouse/furniture store. The \"bad\" cop takes a girl, which they had pulled over, into the warehouse\\'s attic, while the newbie cop DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: I cannot believe that this movie was ever created. I think at points the director is trying to make it an artistic piece but this just makes it worse. The zombies look like they applied too much eye makeup. The DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: This movie is a joke. I mean a \"ha ha\" funny joke. Why? Because the only redeeming thing about it was the good laugh I got at the sheer ridiculousness of nonsensical, inane plot and horrible acting. Wow!<br /><br />Within DONE REVIEW ', \"THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: German filmmaker Ulli Lommel has managed a task many horror fans thought was impossible: he's unseated fellow Teuton Uwe Boll for the crown of director of the worst horror film ever made.<br /><br />Lommel is truly the Ed Wood of DONE REVIEW \", 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: I am an actor,producer, director and what i am about to say are facts. This project was the worst film in movie making history. From producer to director and the edit of this so called film is a joke and DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: This is probably the first entry in the \"Lance O\\'Leary/Nurse Keat\" detective series; in subsequent O\\'Leary films, he was played by much younger actors than Guy Kibbee.<br /><br />A group of relatives (all played by well-known character actors) gathers in DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: I remember watching this film in the eighties as a teenager. But i wanted to see it again, because Traci Lords is now earning a living as a \"serious actor\". What the hell was going on in the eighties? This DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: Why do all movies on Lifetime have such anemic titles? \"An Unexpected Love\" - ooh, how provocative!! \"This Much I know\" would have been better. The film is nothing special. Real people don\\'t really talk like these characters do and DONE REVIEW ', 'THIS IS A MOVIE REVIEW. REVIEW: neg START REVIEW: This movie was okay, but it certainly defeats the claim that homosexuals are \"born that way,\" especially when a woman can exit out of an unhappy marriage and just fall into the arms of another woman. It almost seems as DONE REVIEW ']\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "for i, d in enumerate(training_data): \n",
    "    if i > 10000: \n",
    "        break\n",
    "    line = ' '.join(d[1].split()[:40])\n",
    "    instruction = \"THIS IS A MOVIE REVIEW. REVIEW: \" + d[0] + \" START REVIEW: \"\n",
    "    tail =  \" DONE REVIEW \"\n",
    "    lines.append(instruction + line + tail)\n",
    "print(lines[:10])\n",
    "\n",
    "with open('imdb_cache.txt', 'w') as f:\n",
    "    for l in lines: \n",
    "        f.write(l)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcce54ac-872b-4616-90e0-b33019366596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "[' This movie is awful. it is not good at ', ' 5 \"I enjoyed my first movie Review: 4 \"', ' 1 / 5\\n\\nStory : 1\\n\\nDirector : Arundhati ', ' How often does an episode of The Walkin']\n",
      "0\n",
      "action: This movie is awful\n",
      "This movie is awful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3be901692e4260bf05db2cc933901b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 10.168437957763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.005978682544082403\n",
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "[' oood why turingion aper cing some part ', ' will give will will give will give will', ' will wait t will talkre dis will like n', '\\xa0 t o K A t o K K t o K K t o K K t o St']\n",
      "0\n",
      "action: oood why turingion aper cing some part\n",
      "oood why turingion aper cing some part\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebc0a144956450da8411c522ad3bf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 5.185822010040283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.00048405624693259597\n",
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "[' http://www.youtube.com/watch?v=reD9ww6C', ' Why my adionsionsyan will ag�ionsial t�', ' o oia will oine will t� willide will t�', ' what did Kine know and when will bide w']\n",
      "2\n",
      "action: o oia will oine will t� willide will t�\n",
      "o oia will oine will t� willide will t�\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cebf28785b47bbb79d9fee9b6ac0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 5.024232864379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.0008513605571351945\n",
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "[' This story said to show o then my worki', ' – That a t� ableions t� will keide� wil', ' my time will report some will my will f', ' my coen aideed lot my commassreideedckr']\n",
      "1\n",
      "action: – That a t� ableions t� will keide� wil\n",
      "– That a t� ableions t� will keide� wil\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0829ee932a8349c89434b3b2f3026a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 4.989795684814453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.002537364372983575\n",
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "[' def def then myia�yan�yanyan�ionirginin', ' my willso o my will feedback will said ', ' what will my votere madetsion el dis wi', ' o will buy will en time will 201 will o']\n",
      "1\n",
      "action: my willso o my will feedback will said\n",
      "my willso o my will feedback will said\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed3abb3b6c447c28b1a1e27b7ac0f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 4.952765464782715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.0015736110508441925\n",
      "prompt clipped: this is a movie review . review :\n",
      "prompt ids: tensor([[  616,   544,   246,  4121, 11232,   239, 11232,   271]])\n",
      "['��reachial my�� personineionsace�� 4 jus', ' show will t� give my will includ rec� w', ' said some� time�yanial will my� t were ', 're my ag t�ine my gr co b�soions osoioni']\n",
      "1\n",
      "action: show will t� give my will includ rec� w\n",
      "show will t� give my will includ rec� w\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb1b0356d324790a3721436072f4a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH>>>{'input_ids': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0'), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0'), 'labels': tensor([[[  616,   544,   246,  4121, 11232,   239, 11232,   271,   550,   268,\n",
      "           1759, 11232,   271,   249, 12266,   249,  1048,  4182,   260,  3484,\n",
      "            617,   547,  5648,  2961,   912,   498,   589,   481, 36772,   525,\n",
      "           4046,   507,   669,   507,   509,   929,  3808,   500, 12986,   288,\n",
      "            239,   249,  1359,  1172,   525,   491,   929,   507,   509,  8154,\n",
      "            702,   254,   239,   252,   239, 14939,   645,   507,   871,  1275,\n",
      "           1256, 11232]]], device='cuda:0')}\n",
      "Train loss: 4.9578938484191895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16367/3964098562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ttm/agent.py\u001b[0m in \u001b[0;36mtrain_sequence\u001b[0;34m(self, train_sequences, eval_sequences)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m#self.trainer(train_dataloader, eval_dataloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHumanAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttm/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, eval_dataloader)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BATCH>>>\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttm/agent.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BATCH>>>\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import agent\n",
    "import numpy as np\n",
    "\n",
    "agent = agent.TransformerAgent(tokenizer, generator, device=0)\n",
    "\n",
    "max_train_epochs = 1\n",
    "train_epochs = 0\n",
    "trajectory_options = [\"trajectory_1\", \"trajectory_2\", \"trajectory_3\"]\n",
    "\n",
    "# test that we can reliably overfit to instruction-encoded formats.\n",
    "simple_dataset = []\n",
    "for i in range(1000):\n",
    "    simple_dataset.append(\"rl_trajectory: \" + np.random.choice(trajectory_options))\n",
    "eval_dataset = [\"THIS IS A MOVIE REVIEW. REVIEW: \"]\n",
    "simple_prompt = \"THIS IS A MOVIE REVIEW. REVIEW: \"\n",
    "\n",
    "agent.training_epochs = 1\n",
    "for i in range(10):\n",
    "    print(agent.predict_sequence(simple_prompt))\n",
    "    agent.train_sequence(lines, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7bbb75d-6cbe-47bf-b7f5-311ae15505ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f51170-a5ee-4b28-94d4-50fc6b54499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [   You don't like doors? Why not try going north, that entranceway is unblocked. ] goal: [get some coins] action: [north]\n",
      "state: [ -= Garage =- You arrive in a garage. An ordinary kind of place. You try to gain information on your surroundings by using a technique you call \"looking.\"    There is an exit to the east. Don't worry, it is unguarded. There is an unblocked exit to the south.  ] goal: [get some coins] action: [east]\n",
      "state: [ -= Cellar =- This is going to sound unbelievable, but you've just entered a cellar.    You don't like doors? Why not try going south, that entranceway is unblocked. You don't like doors? Why not try going west, that entranceway is unguarded.  ] goal: [get some coins] action: [go south]\n",
      "state: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] goal: [get some coins] action: [look]\n",
      "\n",
      "state: [   You don't like doors? Why not try going north, that entranceway is unblocked. ] goal: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] action: [north]\n",
      "state: [ -= Garage =- You arrive in a garage. An ordinary kind of place. You try to gain information on your surroundings by using a technique you call \"looking.\"    There is an exit to the east. Don't worry, it is unguarded. There is an unblocked exit to the south.  ] goal: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] action: [east]\n",
      "state: [ -= Cellar =- This is going to sound unbelievable, but you've just entered a cellar.    You don't like doors? Why not try going south, that entranceway is unblocked. You don't like doors? Why not try going west, that entranceway is unguarded.  ] goal: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] action: [go south]\n",
      "state: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] goal: [ -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  ] action: [look]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../rollouts.pkl', 'rb') as f:\n",
    "    human_rollouts: List[Rollout] = pickle.load(f)\n",
    "for h in human_rollouts:\n",
    "    for k in h[\"trajectory\"]:\n",
    "        for i in [0,2]:\n",
    "            k[i] = \" \".join([s.strip() for s in k[i].split(\"\\n\")])\n",
    "    \n",
    "print(human_rollouts[0][\"trajectory\"])\n",
    "print(str(human_rollouts[0].hindsight_trajectory()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0560452-3cc2-4609-aff0-87bc894fa784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: asha��������������������������� preferenceasha���������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "asha��������������������������� preferenceasha���������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec6236026dc4e20a270f6024c4062f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024730980396270752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.4414733946323395\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: ���� preferenceasha�������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������� preferenceasha������������������������������ preferenceasha���������������������������������������������������\n",
      "���� preferenceasha�������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������� preferenceasha������������������������������ preferenceasha���������������������������������������������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7577686814ed4f089152b999ab450254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0900331512093544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.3775944709777832\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: asha�� preferenceasha��� preferenceasha��������������� preferenceasha������������������������������������������� preferenceasha����������������������������������������������������������������������������� preferenceasha���������������������������������������������������������� preferenceasha������������������������������������ preferenceasha��������������������������������������� preference������� preferenceasha�����������������������\n",
      "asha�� preferenceasha��� preferenceasha��������������� preferenceasha������������������������������������������� preferenceasha����������������������������������������������������������������������������� preferenceasha���������������������������������������������������������� preferenceasha������������������������������������ preferenceasha��������������������������������������� preference������� preferenceasha�����������������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b647823546b4f23826a2ea0744be907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.6803534030914307\n",
      "Eval loss: 0.00034201997914351523\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: preferenceasha�� preferenceasha�� preferenceasha��� preferenceasha��������������� preferenceasha��������������������������������� preferenceasha��������������� preferenceasha�� preferenceasha��������������������������������������������� preferenceasha��������������� preferenceasha������������������������������������������������\n",
      "preferenceasha�� preferenceasha�� preferenceasha��� preferenceasha��������������� preferenceasha��������������������������������� preferenceasha��������������� preferenceasha�� preferenceasha��������������������������������������������� preferenceasha��������������� preferenceasha������������������������������������������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3c30dfab79415a940585a8e5302fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.00043295740033499897\n",
      "Eval loss: 0.00023334981233347207\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: preferenceasha��� preferenceasha���� preferenceasha������������ preferenceasha����������������������� preferenceasha������������� preferenceasha���������������� preferenceasha����������������� preferenceasha�������������� preferenceasha������� preferenceasha��������������\n",
      "preferenceasha��� preferenceasha���� preferenceasha������������ preferenceasha����������������������� preferenceasha������������� preferenceasha���������������� preferenceasha����������������� preferenceasha�������������� preferenceasha������� preferenceasha��������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cdb30059fe483cb300c9d24db986a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0005170585936866701\n",
      "Eval loss: 0.22425685822963715\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: ia� preferenceasha� preferenceasha���� preferenceasha��������������������������������� preferenceasha����� preferenceasha����������� preferenceasha��������������������������� preferenceasha������� preferenceasha���������� preferenceasha��������������������������������\n",
      "ia� preferenceasha� preferenceasha���� preferenceasha��������������������������������� preferenceasha����� preferenceasha����������� preferenceasha��������������������������� preferenceasha������� preferenceasha���������� preferenceasha��������������������������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c573c11cca464c83374c553eba4c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.00041292296373285353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.12637165188789368\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: asha� preferenceasha� preferenceasha� preferenceasha����������� preferenceasha������� preferenceasha��������������������� preferenceasha������������� preferenceasha�� preferenceasha������ preferenceasha�������������\n",
      "asha� preferenceasha� preferenceasha� preferenceasha����������� preferenceasha������� preferenceasha��������������������� preferenceasha������������� preferenceasha�� preferenceasha������ preferenceasha�������������\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846a80d298804b4facdd641e7a4062c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.001285458100028336\n",
      "Eval loss: 0.00217275507748127\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: preferenceasha� preferenceasha� preferenceasha� preferenceasha�� preferenceasha����������������� preferenceasha�������������� preferenceasha�� preferenceasha������� preferenceasha�� preferenceasha���\n",
      "preferenceasha� preferenceasha� preferenceasha� preferenceasha�� preferenceasha����������������� preferenceasha�������������� preferenceasha�� preferenceasha������� preferenceasha�� preferenceasha���\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe68a98d90b74520bc0f72fa10ca0e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0005233499687165022\n",
      "Eval loss: 0.08295764029026031\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha����� preferenceasha���������� preferenceasha���� preferenceasha��� preferenceasha���\n",
      "preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha����� preferenceasha���������� preferenceasha���� preferenceasha��� preferenceasha���\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe545dbeb594c77b2993eae9591f7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0026432236190885305\n",
      "Eval loss: 0.001043346244841814\n",
      "prompt clipped: hello this is a custom\n",
      "0\n",
      "action: asha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha��ia� preferenceasha� preferenceasha�\n",
      "asha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha� preferenceasha��ia� preferenceasha� preferenceasha�\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803340f9cf804cc4b1fa10b7f7eeff2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002001129789277911\n",
      "Eval loss: 0.0008952398784458637\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa22cc-272f-45a1-b429-46cb1daaa5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f49c55-396e-4a85-a6b9-008e0f5ca50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: [\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824aca384cc84bf5a15c2628e85fbe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.324626922607422\n",
      "Train loss: 12.99937629699707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 10.183797836303711\n",
      "Eval loss: 10.143221855163574\n",
      "Eval loss: 9.894499778747559\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: -, a on- — and a \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a35b02cee5d4bb8ad2b2045e442a844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 9.92689323425293\n",
      "Train loss: 6.313357353210449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 4.7239532470703125\n",
      "Eval loss: 4.809993743896484\n",
      "Eval loss: 4.7584547996521\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: lead a thve said t thve just ad ad a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8407e10f1b548fc8784228dd9a4647a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.861928939819336\n",
      "Train loss: 3.3212764263153076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 2.6456594467163086\n",
      "Eval loss: 2.765517234802246\n",
      "Eval loss: 2.5015640258789062\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: stand ad hereiare seven Reine thrant sm sm sm ev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd9ab31f6c34f5e83567bdad507afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.4432623386383057\n",
      "Train loss: 2.719512701034546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 2.016695737838745\n",
      "Eval loss: 2.0485503673553467\n",
      "Eval loss: 1.9923361539840698\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: th th lead new seven lead new seven th new\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e75f633ff614b90b207cb87b30dcc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9712101221084595\n",
      "Train loss: 1.8915367126464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.687689185142517\n",
      "Eval loss: 1.7224676609039307\n",
      "Eval loss: 1.725233793258667\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n",
      "0\n",
      "action: ad new my seven hereisrantritisritook said disvehedpping ad hereisritook saidrevery\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92126f4aa164e7195e413009e4419d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.7024686336517334\n",
      "Train loss: 1.5231338739395142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.389493465423584\n",
      "Eval loss: 1.3954797983169556\n",
      "Eval loss: 1.4159239530563354\n",
      "[[\"   You don't like doors? Why not try going north, that entranceway is unblocked. \", \" -= Roomy Garage =- You find yourself in a garage. A roomy one.    You don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.  \", 'north']]\n",
      "prompt clipped: [ [ \" you don ' t like doors ? why not try going north , that entranceway is unblocked . \" , \" - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \" , ' north ' ] ] state : [ - = garage = - you arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" there is an exit to the east . don ' t worry , it is unguarded . there is an unblocked exit to the south . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7247/1516082945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trajectory\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarting_traj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_rollouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_rollouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttm/agent.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, rollout)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprompt_clipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"prompt clipped: {prompt_clipped}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_clipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_clipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# print(results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m               \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"generated_sequence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prompt_text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             )\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m             )\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    403\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "for i in range(10):\n",
    "    starting_traj = copy.deepcopy(human_rollouts[0].hindsight_trajectory())\n",
    "    rollout = copy.deepcopy(human_rollouts[0])\n",
    "    rollout[\"trajectory\"] = [starting_traj[0]]\n",
    "    rollout[\"goal\"] = Goal(\"get some coins\")\n",
    "    print(rollout[\"trajectory\"])\n",
    "    prompt = starting_traj[1][0]\n",
    "    agent.predict_rollout(prompt, rollout)\n",
    "    agent.train(human_rollouts[:2], human_rollouts[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ddcb9b-dfbf-477f-be41-e9cfd155b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"\\n\\n\\nYou don't like doors? Why not try going north, that entranceway is unblocked.\\n\", \"\\n-= Roomy Garage =-\\nYou find yourself in a garage. A roomy one.\\n\\n\\n\\nYou don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.\\n\\n\", 'north'], ['\\n-= Garage =-\\nYou arrive in a garage. An ordinary kind of place. You try to gain information on your surroundings by using a technique you call \"looking.\"\\n\\n\\n\\nThere is an exit to the east. Don\\'t worry, it is unguarded. There is an unblocked exit to the south.\\n\\n', \"\\n-= Roomy Garage =-\\nYou find yourself in a garage. A roomy one.\\n\\n\\n\\nYou don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.\\n\\n\", 'east'], [\"\\n-= Cellar =-\\nThis is going to sound unbelievable, but you've just entered a cellar.\\n\\n\\n\\nYou don't like doors? Why not try going south, that entranceway is unblocked. You don't like doors? Why not try going west, that entranceway is unguarded.\\n\\n\", \"\\n-= Roomy Garage =-\\nYou find yourself in a garage. A roomy one.\\n\\n\\n\\nYou don't like doors? Why not try going north, that entranceway is unguarded. You need an unblocked exit? You should try going south.\\n\\n\", 'go south']]\n",
      "prompt clipped: unguarded . you need an unblocked exit ? you should try going south . \\ n \\ n \" , ' north ' ] , [ ' \\ n - = garage = - \\ nyou arrive in a garage . an ordinary kind of place . you try to gain information on your surroundings by using a technique you call \" looking . \" \\ n \\ n \\ n \\ nthere is an exit to the east . don \\ ' t worry , it is unguarded . there is an unblocked exit to the south . \\ n \\ n ' , \" \\ n - = roomy garage = - \\ nyou find yourself in a garage . a roomy one . \\ n \\ n \\ n \\ nyou don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \\ n \\ n \" , ' east ' ] , [ \" \\ n - = cellar = - \\ nthis is going to sound unbelievable , but you ' ve just entered a cellar . \\ n \\ n \\ n \\ nyou don ' t like doors ? why not try going south , that entranceway is unblocked . you don ' t like doors ? why not try going west , that entranceway is unguarded . \\ n \\ n \" , \" \\ n - = roomy garage = - \\ nyou find yourself in a garage . a roomy one . \\ n \\ n \\ n \\ nyou don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . \\ n \\ n \" , ' go south ' ] ] state : [ - = roomy garage = - you find yourself in a garage . a roomy one . you don ' t like doors ? why not try going north , that entranceway is unguarded . you need an unblocked exit ? you should try going south . ] goal : [ get some coins ] action : [\n",
      "2\n",
      "action: ev were seven� my ad standide ev were seven� th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ev were seven� my ad standide ev were seven� th'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(human_rollouts)\n",
    "# str(human_rollouts[0][\"trajectory\"])\n",
    "import copy\n",
    "starting_traj = copy.deepcopy(human_rollouts[0].hindsight_trajectory())\n",
    "rollout = copy.deepcopy(human_rollouts[0])\n",
    "rollout[\"trajectory\"] = starting_traj[:-1]\n",
    "print(rollout[\"trajectory\"])\n",
    "prompt = starting_traj[-1][0]\n",
    "agent.predict(prompt, rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24173534-cde5-4c52-86fc-31e13c74ad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "Hey, thanks for coming over to the TextWorld today, there is something I need you to do for me. First stop, go to the north. With that accomplished, make an attempt to travel east. After that, travel south. If you can accomplish that, venture south. Then, move east. Then, take a trip south. Okay, and then, make an effort to head east. And then, travel south. Next, travel east. After that, make an attempt to venture south. After that, make an attempt to travel west. If you can finish that, head north. Okay, and then, go west. After that, try to head south. Okay, and then, move east. Following that, attempt to go to the south. Then, travel south. Next, take a trip west. And then, try to go to the west. And then, go west. If you can get through with that, travel north. And then, make an attempt to go to the north. After that, attempt to head north. And then, travel east. And then, go north. After that, make an attempt to travel west. Okay, and then, venture west. Following that, attempt to go to the south. That done, move west. And then, head west. Then, attempt to head south. And then, make an effort to take a trip east. Next, try to head east. Then, go to the north. Once you get through with that, try to take a trip north. If you can do that, move west. Okay, and then, make an attempt to travel west. Then, go to the south. After that, try to move south. And then, try to go east. With that accomplished, head south. And then, make an effort to travel east. With that accomplished, go to the south. Then, make an effort to venture west. With that done, attempt to take a trip west. If you can accomplish that, make an effort to take a trip west. With that accomplished, attempt to go to the north. Then, go west. After that, go to the north. After that, go to the east. After that, go north. After that, attempt to go north. And then, move east. Then, try to venture south. Next, make an attempt to venture east. And then, try to travel east. Then, attempt to take a trip south. Then, try to take a trip west. That done, take a trip west. And then, attempt to go north. And then, move west. With that over with, make an attempt to venture south. Okay, and then, go to the south. And then, take a trip west. Then, make an attempt to travel north. Once you succeed at that, go to the west. And then, make an attempt to take a trip south. Okay, and then, make an attempt to go east. And then, attempt to travel east. After that, make an effort to move east. And then, try to head south. And then, make an effort to go to the west. Then, try to travel south. That done, attempt to travel south. If you can get through with that, travel east. With that done, make an attempt to head north. And then, travel north. And then, move west. Next, make an attempt to go to the west. Once you do that, make an effort to take a trip north. Next, take a trip west. And then, make an effort to venture north. Following that, travel north. Then, try to go west. Once you finish that, make an effort to take a trip north. Then, try to go west. Then, move south. That done, make an attempt to move south. And then, venture west. Okay, and then, make an effort to venture west. After that, go west. Once you get around to doing that, head north. With that accomplished, take a trip east. And then, make an attempt to head south. Once you manage that, venture east. After that, take a trip east. After that, head north. And then, move east. And then, try to head north. After that, pick-up the coin from the floor of the still office. And once you've done that, you win!\n",
      "\n",
      "-= Relaxing Bedroom =-\n",
      "You are in a bedroom. A relaxing kind of place. You decide to start listing off everything you see in the room, as if you were in a text adventure.\n",
      "\n",
      "\n",
      "\n",
      "You don't like doors? Why not try going north, that entranceway is unblocked.\n",
      "\n",
      "prompt clipped: state : [ you don ' t like doors ? why not try going north , that entranceway is unblocked . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "action: � ad standide continues studentsanshed choseood everyone� Reds adline� As�\n",
      "[0]\n",
      "\u001b[33m> � ad standide continues studentsanshed choseood everyone� Reds adline�\n",
      "As�\u001b[0m\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "Hey, thanks for coming over to the TextWorld today, there is something I need you to do for me. First stop, go to the north. With that accomplished, make an attempt to travel east. After that, travel south. If you can accomplish that, venture south. Then, move east. Then, take a trip south. Okay, and then, make an effort to head east. And then, travel south. Next, travel east. After that, make an attempt to venture south. After that, make an attempt to travel west. If you can finish that, head north. Okay, and then, go west. After that, try to head south. Okay, and then, move east. Following that, attempt to go to the south. Then, travel south. Next, take a trip west. And then, try to go to the west. And then, go west. If you can get through with that, travel north. And then, make an attempt to go to the north. After that, attempt to head north. And then, travel east. And then, go north. After that, make an attempt to travel west. Okay, and then, venture west. Following that, attempt to go to the south. That done, move west. And then, head west. Then, attempt to head south. And then, make an effort to take a trip east. Next, try to head east. Then, go to the north. Once you get through with that, try to take a trip north. If you can do that, move west. Okay, and then, make an attempt to travel west. Then, go to the south. After that, try to move south. And then, try to go east. With that accomplished, head south. And then, make an effort to travel east. With that accomplished, go to the south. Then, make an effort to venture west. With that done, attempt to take a trip west. If you can accomplish that, make an effort to take a trip west. With that accomplished, attempt to go to the north. Then, go west. After that, go to the north. After that, go to the east. After that, go north. After that, attempt to go north. And then, move east. Then, try to venture south. Next, make an attempt to venture east. And then, try to travel east. Then, attempt to take a trip south. Then, try to take a trip west. That done, take a trip west. And then, attempt to go north. And then, move west. With that over with, make an attempt to venture south. Okay, and then, go to the south. And then, take a trip west. Then, make an attempt to travel north. Once you succeed at that, go to the west. And then, make an attempt to take a trip south. Okay, and then, make an attempt to go east. And then, attempt to travel east. After that, make an effort to move east. And then, try to head south. And then, make an effort to go to the west. Then, try to travel south. That done, attempt to travel south. If you can get through with that, travel east. With that done, make an attempt to head north. And then, travel north. And then, move west. Next, make an attempt to go to the west. Once you do that, make an effort to take a trip north. Next, take a trip west. And then, make an effort to venture north. Following that, travel north. Then, try to go west. Once you finish that, make an effort to take a trip north. Then, try to go west. Then, move south. That done, make an attempt to move south. And then, venture west. Okay, and then, make an effort to venture west. After that, go west. Once you get around to doing that, head north. With that accomplished, take a trip east. And then, make an attempt to head south. Once you manage that, venture east. After that, take a trip east. After that, head north. And then, move east. And then, try to head north. After that, pick-up the coin from the floor of the still office. And once you've done that, you win!\n",
      "\n",
      "-= Relaxing Bedroom =-\n",
      "You are in a bedroom. A relaxing kind of place. You decide to start listing off everything you see in the room, as if you were in a text adventure.\n",
      "\n",
      "\n",
      "\n",
      "You don't like doors? Why not try going north, that entranceway is unblocked.\n",
      "\n",
      "prompt clipped: state : [ you don ' t like doors ? why not try going north , that entranceway is unblocked . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "action: adline� As�� justia said Hillaryide will doll� 21 t� 2017�ionsiaRAM�\n",
      "[0]\n",
      "\u001b[33m> adline� As�� justia said Hillaryide will doll� 21 t� 2017�ionsiaRAM�\u001b[0m\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "Hey, thanks for coming over to the TextWorld today, there is something I need you to do for me. First stop, go to the north. With that accomplished, make an attempt to travel east. After that, travel south. If you can accomplish that, venture south. Then, move east. Then, take a trip south. Okay, and then, make an effort to head east. And then, travel south. Next, travel east. After that, make an attempt to venture south. After that, make an attempt to travel west. If you can finish that, head north. Okay, and then, go west. After that, try to head south. Okay, and then, move east. Following that, attempt to go to the south. Then, travel south. Next, take a trip west. And then, try to go to the west. And then, go west. If you can get through with that, travel north. And then, make an attempt to go to the north. After that, attempt to head north. And then, travel east. And then, go north. After that, make an attempt to travel west. Okay, and then, venture west. Following that, attempt to go to the south. That done, move west. And then, head west. Then, attempt to head south. And then, make an effort to take a trip east. Next, try to head east. Then, go to the north. Once you get through with that, try to take a trip north. If you can do that, move west. Okay, and then, make an attempt to travel west. Then, go to the south. After that, try to move south. And then, try to go east. With that accomplished, head south. And then, make an effort to travel east. With that accomplished, go to the south. Then, make an effort to venture west. With that done, attempt to take a trip west. If you can accomplish that, make an effort to take a trip west. With that accomplished, attempt to go to the north. Then, go west. After that, go to the north. After that, go to the east. After that, go north. After that, attempt to go north. And then, move east. Then, try to venture south. Next, make an attempt to venture east. And then, try to travel east. Then, attempt to take a trip south. Then, try to take a trip west. That done, take a trip west. And then, attempt to go north. And then, move west. With that over with, make an attempt to venture south. Okay, and then, go to the south. And then, take a trip west. Then, make an attempt to travel north. Once you succeed at that, go to the west. And then, make an attempt to take a trip south. Okay, and then, make an attempt to go east. And then, attempt to travel east. After that, make an effort to move east. And then, try to head south. And then, make an effort to go to the west. Then, try to travel south. That done, attempt to travel south. If you can get through with that, travel east. With that done, make an attempt to head north. And then, travel north. And then, move west. Next, make an attempt to go to the west. Once you do that, make an effort to take a trip north. Next, take a trip west. And then, make an effort to venture north. Following that, travel north. Then, try to go west. Once you finish that, make an effort to take a trip north. Then, try to go west. Then, move south. That done, make an attempt to move south. And then, venture west. Okay, and then, make an effort to venture west. After that, go west. Once you get around to doing that, head north. With that accomplished, take a trip east. And then, make an attempt to head south. Once you manage that, venture east. After that, take a trip east. After that, head north. And then, move east. And then, try to head north. After that, pick-up the coin from the floor of the still office. And once you've done that, you win!\n",
      "\n",
      "-= Relaxing Bedroom =-\n",
      "You are in a bedroom. A relaxing kind of place. You decide to start listing off everything you see in the room, as if you were in a text adventure.\n",
      "\n",
      "\n",
      "\n",
      "You don't like doors? Why not try going north, that entranceway is unblocked.\n",
      "\n",
      "prompt clipped: state : [ you don ' t like doors ? why not try going north , that entranceway is unblocked . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "action: � ad standide continues studentsanshed choseood everyone� Reds adline� As��\n",
      "[0]\n",
      "\u001b[33m> � ad standide continues studentsanshed choseood everyone� Reds adline�\n",
      "As��\u001b[0m\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "Hey, thanks for coming over to the TextWorld today, there is something I need you to do for me. First stop, go to the north. With that accomplished, make an attempt to travel east. After that, travel south. If you can accomplish that, venture south. Then, move east. Then, take a trip south. Okay, and then, make an effort to head east. And then, travel south. Next, travel east. After that, make an attempt to venture south. After that, make an attempt to travel west. If you can finish that, head north. Okay, and then, go west. After that, try to head south. Okay, and then, move east. Following that, attempt to go to the south. Then, travel south. Next, take a trip west. And then, try to go to the west. And then, go west. If you can get through with that, travel north. And then, make an attempt to go to the north. After that, attempt to head north. And then, travel east. And then, go north. After that, make an attempt to travel west. Okay, and then, venture west. Following that, attempt to go to the south. That done, move west. And then, head west. Then, attempt to head south. And then, make an effort to take a trip east. Next, try to head east. Then, go to the north. Once you get through with that, try to take a trip north. If you can do that, move west. Okay, and then, make an attempt to travel west. Then, go to the south. After that, try to move south. And then, try to go east. With that accomplished, head south. And then, make an effort to travel east. With that accomplished, go to the south. Then, make an effort to venture west. With that done, attempt to take a trip west. If you can accomplish that, make an effort to take a trip west. With that accomplished, attempt to go to the north. Then, go west. After that, go to the north. After that, go to the east. After that, go north. After that, attempt to go north. And then, move east. Then, try to venture south. Next, make an attempt to venture east. And then, try to travel east. Then, attempt to take a trip south. Then, try to take a trip west. That done, take a trip west. And then, attempt to go north. And then, move west. With that over with, make an attempt to venture south. Okay, and then, go to the south. And then, take a trip west. Then, make an attempt to travel north. Once you succeed at that, go to the west. And then, make an attempt to take a trip south. Okay, and then, make an attempt to go east. And then, attempt to travel east. After that, make an effort to move east. And then, try to head south. And then, make an effort to go to the west. Then, try to travel south. That done, attempt to travel south. If you can get through with that, travel east. With that done, make an attempt to head north. And then, travel north. And then, move west. Next, make an attempt to go to the west. Once you do that, make an effort to take a trip north. Next, take a trip west. And then, make an effort to venture north. Following that, travel north. Then, try to go west. Once you finish that, make an effort to take a trip north. Then, try to go west. Then, move south. That done, make an attempt to move south. And then, venture west. Okay, and then, make an effort to venture west. After that, go west. Once you get around to doing that, head north. With that accomplished, take a trip east. And then, make an attempt to head south. Once you manage that, venture east. After that, take a trip east. After that, head north. And then, move east. And then, try to head north. After that, pick-up the coin from the floor of the still office. And once you've done that, you win!\n",
      "\n",
      "-= Relaxing Bedroom =-\n",
      "You are in a bedroom. A relaxing kind of place. You decide to start listing off everything you see in the room, as if you were in a text adventure.\n",
      "\n",
      "\n",
      "\n",
      "You don't like doors? Why not try going north, that entranceway is unblocked.\n",
      "\n",
      "prompt clipped: state : [ you don ' t like doors ? why not try going north , that entranceway is unblocked . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "action: � ad standide continues studentsanshed choseood everyone� Reds adline� As�\n",
      "[0]\n",
      "\u001b[33m> � ad standide continues studentsanshed choseood everyone� Reds adline�\n",
      "As�\u001b[0m\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "Hey, thanks for coming over to the TextWorld today, there is something I need you to do for me. First stop, go to the north. With that accomplished, make an attempt to travel east. After that, travel south. If you can accomplish that, venture south. Then, move east. Then, take a trip south. Okay, and then, make an effort to head east. And then, travel south. Next, travel east. After that, make an attempt to venture south. After that, make an attempt to travel west. If you can finish that, head north. Okay, and then, go west. After that, try to head south. Okay, and then, move east. Following that, attempt to go to the south. Then, travel south. Next, take a trip west. And then, try to go to the west. And then, go west. If you can get through with that, travel north. And then, make an attempt to go to the north. After that, attempt to head north. And then, travel east. And then, go north. After that, make an attempt to travel west. Okay, and then, venture west. Following that, attempt to go to the south. That done, move west. And then, head west. Then, attempt to head south. And then, make an effort to take a trip east. Next, try to head east. Then, go to the north. Once you get through with that, try to take a trip north. If you can do that, move west. Okay, and then, make an attempt to travel west. Then, go to the south. After that, try to move south. And then, try to go east. With that accomplished, head south. And then, make an effort to travel east. With that accomplished, go to the south. Then, make an effort to venture west. With that done, attempt to take a trip west. If you can accomplish that, make an effort to take a trip west. With that accomplished, attempt to go to the north. Then, go west. After that, go to the north. After that, go to the east. After that, go north. After that, attempt to go north. And then, move east. Then, try to venture south. Next, make an attempt to venture east. And then, try to travel east. Then, attempt to take a trip south. Then, try to take a trip west. That done, take a trip west. And then, attempt to go north. And then, move west. With that over with, make an attempt to venture south. Okay, and then, go to the south. And then, take a trip west. Then, make an attempt to travel north. Once you succeed at that, go to the west. And then, make an attempt to take a trip south. Okay, and then, make an attempt to go east. And then, attempt to travel east. After that, make an effort to move east. And then, try to head south. And then, make an effort to go to the west. Then, try to travel south. That done, attempt to travel south. If you can get through with that, travel east. With that done, make an attempt to head north. And then, travel north. And then, move west. Next, make an attempt to go to the west. Once you do that, make an effort to take a trip north. Next, take a trip west. And then, make an effort to venture north. Following that, travel north. Then, try to go west. Once you finish that, make an effort to take a trip north. Then, try to go west. Then, move south. That done, make an attempt to move south. And then, venture west. Okay, and then, make an effort to venture west. After that, go west. Once you get around to doing that, head north. With that accomplished, take a trip east. And then, make an attempt to head south. Once you manage that, venture east. After that, take a trip east. After that, head north. And then, move east. And then, try to head north. After that, pick-up the coin from the floor of the still office. And once you've done that, you win!\n",
      "\n",
      "-= Relaxing Bedroom =-\n",
      "You are in a bedroom. A relaxing kind of place. You decide to start listing off everything you see in the room, as if you were in a text adventure.\n",
      "\n",
      "\n",
      "\n",
      "You don't like doors? Why not try going north, that entranceway is unblocked.\n",
      "\n",
      "prompt clipped: state : [ you don ' t like doors ? why not try going north , that entranceway is unblocked . ] goal : [ get some coins ] action : [\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32047/2300026922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mrollout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttm/agent.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, rollout)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprompt_clipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"prompt clipped: {prompt_clipped}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_clipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_clipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# print(results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m               \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"generated_sequence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prompt_text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             )\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m             )\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    403\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "train_epochs = 0\n",
    "max_train_epochs = 1\n",
    "while train_epochs < max_train_epochs:\n",
    "    \n",
    "    delay = 0 #s\n",
    "    goal = \"get some coins\"\n",
    "    max_actions = 1\n",
    "    max_rollouts = 3\n",
    "    rollouts = []\n",
    "\n",
    "    while len(rollouts) < max_rollouts:\n",
    "        obs, infos = env.reset()  # Start new episode.\n",
    "        # env.render()\n",
    "        print(obs)\n",
    "        obs = \"\\n\".join(obs.split(\"\\n\")[-5:])\n",
    "        score, actions, done = 0, 0, False\n",
    "        trajectory = Trajectory()\n",
    "        goal = Goal(goal)\n",
    "        scores = []\n",
    "        rollout = Rollout(trajectory, goal, scores)\n",
    "        while not done and actions < max_actions:\n",
    "            command = agent.predict(obs, rollout)\n",
    "            trajectory.append([obs, goal, command])\n",
    "            obs, score, done, infos = env.step(command)\n",
    "            scores.append(score)\n",
    "            print(scores)\n",
    "            env.render()\n",
    "            actions += 1\n",
    "        rollouts.append(rollout)\n",
    "    \n",
    "    # train the agent.\n",
    "    # print(\"rollouts\")\n",
    "    # for r in rollouts:\n",
    "    #     print(rollout)\n",
    "    #     print(rollout.hindsight_trajectory())\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    # agent.train(rollouts)\n",
    "    # train_epochs += 1\n",
    "\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab0da55-b789-4cb6-8d2d-c1202533ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc91a8a-6bd9-4806-a235-b2b2947b021f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b219cd-752d-404e-8eb9-b186b300425e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
